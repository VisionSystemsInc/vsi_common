#!/usr/bin/env bash

if [ -z ${VSI_COMMON_DIR+set} ]; then
  VSI_COMMON_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.."; pwd)"
fi

source "${VSI_COMMON_DIR}/tests/testlib.bsh"
source "${TESTLIB_DIR}/test_utils.bsh"
source "${VSI_COMMON_DIR}/linux/aliases.bsh"
source "${VSI_COMMON_DIR}/linux/cuda_info.bsh"

# Acquired from https://developer.nvidia.com/cuda-toolkit-archive, but some links were broken
# http://developer.download.nvidia.com/compute/cuda/1.0/linux/toolkits/NVIDIA_CUDA_Toolkit_1.0_rhel5_x86_64.run
# http://developer.download.nvidia.com/compute/cuda/1.1/Linux/toolkits/NVIDIA_CUDA_Toolkit_1.1_rhel5_x86_64.run
# http://developer.download.nvidia.com/compute/cuda/2_0/linux/toolkit/NVIDIA_CUDA_Toolkit_2.0_rhel5.1_x86_64.run
# http://developer.download.nvidia.com/compute/compute/cuda/2_2/toolkit/cudatoolkit_2.2_linux_64_rhel5.3.run
# http://developer.download.nvidia.com/compute/compute/cuda/2_2/toolkit/cudatoolkit_2.2_linux_64_rhel5.3.run
# http://developer.download.nvidia.com/compute/compute/cuda/2_2/toolkit/cudatoolkit_2.2_linux_64_rhel5.3.run
# http://developer.download.nvidia.com/compute/compute/cuda/2_2/toolkit/cudatoolkit_2.2_linux_64_rhel5.3.run
# http://developer.download.nvidia.com/compute/compute/cuda/2_2/toolkit/cudatoolkit_2.2_linux_64_rhel5.3.run
# http://developer.download.nvidia.com/compute/compute/cuda/2_3/toolkit/cudatoolkit_2.3_linux_64_rhel5.3.run
# http://developer.download.nvidia.com/compute/compute/cuda/3_0/toolkit/cudatoolkit_3.0_linux_64_rhel5.3.run
# http://developer.download.nvidia.com/compute/compute/cuda/3_1/toolkit/cudatoolkit_3.1_linux_64_rhel5.4.run
# http://developer.download.nvidia.com/compute/compute/cuda/3_2_prod/toolkit/cudatoolkit_3.2.16_linux_64_rhel5.5.run
# http://developer.download.nvidia.com/compute/compute/cuda/4_0/toolkit/cudatoolkit_4.0.17_linux_64_rhel5.5.run
# http://developer.download.nvidia.com/compute/cuda/4_1/rel/toolkit/cudatoolkit_4.1.28_linux_64_rhel5.x.run
# http://developer.download.nvidia.com/compute/compute/cuda/4_0/toolkit/cudatoolkit_4.0.17_linux_64_rhel6.0.run
# http://developer.download.nvidia.com/compute/cuda/4_1/rel/toolkit/cudatoolkit_4.1.28_linux_64_rhel6.x.run
# http://developer.download.nvidia.com/compute/cuda/4_2/rel/toolkit/cudatoolkit_4.2.9_linux_64_rhel5.5.run
# http://developer.download.nvidia.com/compute/cuda/4_2/rel/toolkit/cudatoolkit_4.2.9_linux_64_rhel6.0.run
# http://developer.download.nvidia.com/compute/cuda/5_0/rel-update-1/installers/cuda_5.0.35_linux_64_rhel5.x-1.run
# http://developer.download.nvidia.com/compute/cuda/5_0/rel-update-1/installers/cuda_5.0.35_linux_64_rhel6.x-1.run
# http://developer.download.nvidia.com/compute/cuda/5_5/rel/installers/cuda_5.5.22_linux_64.run
# http://developer.download.nvidia.com/compute/cuda/6_0/rel/installers/cuda_6.0.37_linux_64.run
# http://developer.download.nvidia.com/compute/cuda/6_5/rel/installers/cuda_6.5.14_linux_64.run
# http://developer.download.nvidia.com/compute/cuda/7_0/Prod/local_installers/cuda_7.0.28_linux.run
# http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.18_linux.run
# https://developer.nvidia.com/compute/cuda/8.0/prod/local_installers/cuda_8.0.44_linux-run
# https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda_8.0.61_375.26_linux-run
# https://developer.nvidia.com/compute/cuda/8.0/Prod2/patches/2/cuda_8.0.61.2_linux-run
# https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda_9.0.176_384.81_linux-run
# https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda_9.0.176_384.81_linux-run
# https://developer.nvidia.com/compute/cuda/9.0/Prod/patches/1/cuda_9.0.176.1_linux-run
# https://developer.nvidia.com/compute/cuda/9.0/Prod/patches/2/cuda_9.0.176.2_linux-run
# https://developer.nvidia.com/compute/cuda/9.0/Prod/patches/3/cuda_9.0.176.3_linux-run
# https://developer.nvidia.com/compute/cuda/9.0/Prod/patches/4/cuda_9.0.176.4_linux-run
# https://developer.nvidia.com/compute/cuda/9.1/Prod/local_installers/cuda_9.1.85_387.26_linux
# https://developer.nvidia.com/compute/cuda/9.1/Prod/patches/1/cuda_9.1.85.1_linux
# https://developer.nvidia.com/compute/cuda/9.1/Prod/patches/2/cuda_9.1.85.2_linux
# https://developer.nvidia.com/compute/cuda/9.1/Prod/patches/3/cuda_9.1.85.3_linux
# https://developer.nvidia.com/compute/cuda/9.2/Prod2/local_installers/cuda_9.2.148_396.37_linux
# https://developer.nvidia.com/compute/cuda/9.2/Prod2/patches/1/cuda_9.2.148.1_linux
# https://developer.nvidia.com/compute/cuda/10.0/Prod/local_installers/cuda_10.0.130_410.48_linux
# http://developer.download.nvidia.com/compute/cuda/10.0/Prod/patches/1/cuda_10.0.130.1_linux.run
# https://developer.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda_10.1.105_418.39_linux.run
# https://developer.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda_10.1.168_418.67_linux.run
# https://developer.download.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda_10.1.243_418.87.00_linux.run
# https://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda_10.2.89_440.33.01_linux.run
# http://developer.download.nvidia.com/compute/cuda/11.0.1/local_installers/cuda_11.0.1_450.36.06_linux.run
# http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda_11.0.2_450.51.05_linux.run
# https://developer.download.nvidia.com/compute/cuda/11.0.3/local_installers/cuda_11.0.3_450.51.06_linux.run
# https://developer.download.nvidia.com/compute/cuda/11.1.0/local_installers/cuda_11.1.0_455.23.05_linux.run
# https://developer.download.nvidia.com/compute/cuda/11.1.1/local_installers/cuda_11.1.1_455.32.00_linux.run
# https://developer.download.nvidia.com/compute/cuda/11.2.0/local_installers/cuda_11.2.0_460.27.04_linux.run
# https://developer.download.nvidia.com/compute/cuda/11.2.1/local_installers/cuda_11.2.1_460.32.03_linux.run
# https://developer.download.nvidia.com/compute/cuda/11.2.2/local_installers/cuda_11.2.2_460.32.03_linux.run

##########
# Cuda 1 #
##########
# Cuda 1.0
# --------
nvcc1='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2006 NVIDIA Corporation
Built on Thu_Jun_28_08:21:25_PDT_2007
Cuda compilation tools, release 1.0, V0.2.1221'

# Cuda 1.1
# --------
nvcc11='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2006 NVIDIA Corporation
Built on Fri_Nov_30_01:55:35_PST_2007
Cuda compilation tools, release 1.1, V0.2.1221'

##########
# Cuda 2 #
##########
# Cuda 2.0
# --------
nvcc2='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2007 NVIDIA Corporation
Built on Thu_Jun_19_03:38:28_PDT_2008
Cuda compilation tools, release 2.0, V0.2.1221'

# Cuda 2.1
# --------
nvcc21='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2007 NVIDIA Corporation
Built on Wed_Dec__3_16:25:17_PST_2008
Cuda compilation tools, release 2.1, V0.2.1221'

# Cuda 2.2
# --------
nvcc22='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2009 NVIDIA Corporation
Built on Thu_Apr__9_05:05:52_PDT_2009
Cuda compilation tools, release 2.2, V0.2.1221'

# Cuda 2.3
# --------
nvcc23='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2009 NVIDIA Corporation
Built on Thu_Jul_30_09:24:36_PDT_2009
Cuda compilation tools, release 2.3, V0.2.1221'

##########
# Cuda 3 #
##########
# Cuda 3.0
# --------
nvcc3='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2009 NVIDIA Corporation
Built on Fri_Feb_19_19:12:59_PST_2010
Cuda compilation tools, release 3.0, V0.2.1221'

# Cuda 3.1
# --------
nvcc31='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2010 NVIDIA Corporation
Built on Mon_Jun__7_18:56:31_PDT_2010
Cuda compilation tools, release 3.1, V0.2.1221'

# Cuda 3.2
# --------
nvcc32='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2010 NVIDIA Corporation
Built on Wed_Nov__3_16:16:57_PDT_2010
Cuda compilation tools, release 3.2, V0.2.1221'

##########
# Cuda 4 #
##########
# Cuda 4.0
# --------
nvcc4='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2011 NVIDIA Corporation
Built on Thu_May_12_11:09:45_PDT_2011
Cuda compilation tools, release 4.0, V0.2.1221'

# Cuda 4.1
# --------
nvcc41='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2011 NVIDIA Corporation
Built on Thu_Jan_12_14:41:45_PST_2012
Cuda compilation tools, release 4.1, V0.2.1221'

# Cuda 4.2
# --------
nvcc42='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2012 NVIDIA Corporation
Built on Thu_Apr__5_00:24:31_PDT_2012
Cuda compilation tools, release 4.2, V0.2.1221'

##########
# Cuda 5 #
##########
# Cuda 5.0
# --------
nvcc5='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2012 NVIDIA Corporation
Built on Fri_Sep_21_17:28:58_PDT_2012
Cuda compilation tools, release 5.0, V0.2.1221'

# Cuda 5.5
# --------
nvcc55='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2013 NVIDIA Corporation
Built on Wed_Jul_17_18:36:13_PDT_2013
Cuda compilation tools, release 5.5, V5.5.0'

##########
# Cuda 6 #
##########
# Cuda 6.0
# --------
nvcc6='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2013 NVIDIA Corporation
Built on Thu_Mar_13_11:58:58_PDT_2014
Cuda compilation tools, release 6.0, V6.0.1'

# Cuda 6.5
# --------
nvcc65='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2014 NVIDIA Corporation
Built on Thu_Jul_17_21:41:27_CDT_2014
Cuda compilation tools, release 6.5, V6.5.12'

##########
# Cuda 7 #
##########
# Cuda 7.0
# --------
nvcc7='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2015 NVIDIA Corporation
Built on Mon_Feb_16_22:59:02_CST_2015
Cuda compilation tools, release 7.0, V7.0.27'

# Cuda 7.5
# --------
nvcc75='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2015 NVIDIA Corporation
Built on Tue_Aug_11_14:27:32_CDT_2015
Cuda compilation tools, release 7.5, V7.5.17'
# This didn't start until cuda 7.5
version75='CUDA Version 7.5.18'

##########
# Cuda 8 #
##########
# Cuda 8.0
# --------
nvcc8='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Sun_Sep__4_22:14:01_CDT_2016
Cuda compilation tools, release 8.0, V8.0.44'
version8='CUDA Version 8.0.44'

# Cuda 8.0 GA2
# ------------
nvcc8ga2='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Tue_Jan_10_13:22:03_CST_2017
Cuda compilation tools, release 8.0, V8.0.61'
version8ga='CUDA Version 8.0.61'
version8ga2p2='CUDA Version 8.0.61
CUDA Patch Version 8.0.61.2'

##########
# Cuda 9 #
##########
# Cuda 9.0
# --------
nvcc9='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2017 NVIDIA Corporation
Built on Fri_Sep__1_21:08:03_CDT_2017
Cuda compilation tools, release 9.0, V9.0.176'
version9='CUDA Version 9.0.176'
version9p1='CUDA Version 9.0.176
CUDA Patch Version 9.0.176.1'
# Note patch 2 could be missing patch one, or be in a different order, which
# would actually be kinda bad, cause then patch 2 files were replaced with 1
version9p2='CUDA Version 9.0.176
CUDA Patch Version 9.0.176.1
CUDA Patch Version 9.0.176.2'
version9p3='CUDA Version 9.0.176
CUDA Patch Version 9.0.176.1
CUDA Patch Version 9.0.176.2
CUDA Patch Version 9.0.176.3'
version9p4='CUDA Version 9.0.176
CUDA Patch Version 9.0.176.1
CUDA Patch Version 9.0.176.2
CUDA Patch Version 9.0.176.3
CUDA Patch Version 9.0.176.4'

# Cuda 9.1
# --------
nvcc91='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2017 NVIDIA Corporation
Built on Fri_Nov__3_21:07:56_CDT_2017
Cuda compilation tools, release 9.1, V9.1.85'
version91='CUDA Version 9.1.85'
version91p1='CUDA Version 9.1.85
CUDA Patch Version 9.1.85.1'
version91p2='CUDA Version 9.1.85
CUDA Patch Version 9.1.85.1
CUDA Patch Version 9.1.85.2'
version91p3='CUDA Version 9.1.85
CUDA Patch Version 9.1.85.1
CUDA Patch Version 9.1.85.2
CUDA Patch Version 9.1.85.3'

# Cuda 9.2
# --------
nvcc92='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Tue_Jun_12_23:07:04_CDT_2018
Cuda compilation tools, release 9.2, V9.2.148'
version92='CUDA Version 9.2.148'
version92p1='CUDA Version 9.2.148
CUDA Patch Version 9.2.148.1'

###########
# Cuda 10 #
###########
# Cuda 10.0
# ---------

nvcc10='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130'
version10='CUDA Version 10.0.130'
version10p1='CUDA Version 10.0.130
CUDA Patch Version 10.0.130.1'

# Cuda 10.1
# ---------
nvcc101='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Fri_Feb__8_19:08:17_PST_2019
Cuda compilation tools, release 10.1, V10.1.105'
version101='CUDA Version 10.1.105'

# Cuda 10.1 Update 1
nvcc101u1='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Wed_Apr_24_19:10:27_PDT_2019
Cuda compilation tools, release 10.1, V10.1.168'
version101u1='CUDA Version 10.1.168'

# Cuda 10.1 Update 2
nvcc101u2='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243'
version101u2='CUDA Version 10.1.243'

# Cuda 10.2
# ---------
nvcc102='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Wed_Oct_23_19:24:38_PDT_2019
Cuda compilation tools, release 10.2, V10.2.89'
version102='CUDA Version 10.2.89'

###########
# Cuda 11 #
###########
# Cuda 11.0
# ---------
# 11.0.1rc (now hidden)
nvcc1101='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Wed_May__6_19:09:25_PDT_2020
Cuda compilation tools, release 11.0, V11.0.167
Build cuda_11.0_bu.TC445_37.28358933_0'
# Only installed if docs are installed, from 11.0 on, this is actually the
# version of the "documentation", and which is not covered in the release notes
version1101='CUDA Version 11.0.182'

# 11.0.2 (aka 11.0)
nvcc1102='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Thu_Jun_11_22:26:38_PDT_2020
Cuda compilation tools, release 11.0, V11.0.194
Build cuda_11.0_bu.TC445_37.28540450_0'
version1102='CUDA Version 11.0.207'

# 11.0.3 (aka 11.0 Update 1)
nvcc1103='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Wed_Jul_22_19:09:09_PDT_2020
Cuda compilation tools, release 11.0, V11.0.221
Build cuda_11.0_bu.TC445_37.28845127_0'
version1103='CUDA Version 11.0.228'

# Cuda 11.1
# ---------
# 11.1.0
nvcc111='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Tue_Sep_15_19:10:02_PDT_2020
Cuda compilation tools, release 11.1, V11.1.74
Build cuda_11.1.TC455_06.29069683_0'
# No more version.txt as of 11.1.0
# version111='CUDA Version 11.1.74'

# 11.1.1
nvcc1111='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Mon_Oct_12_20:09:46_PDT_2020
Cuda compilation tools, release 11.1, V11.1.105
Build cuda_11.1.TC455_06.29190527_0'
# version1111='CUDA Version 11.1.105'

# Cuda 11.2
# ---------
# 11.2.0
nvcc112='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Mon_Nov_30_19:08:53_PST_2020
Cuda compilation tools, release 11.2, V11.2.67
Build cuda_11.2.r11.2/compiler.29373293_0'
# version112='CUDA Version 11.2.67'

# 11.2.1
nvcc1121='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Thu_Jan_28_19:32:09_PST_2021
Cuda compilation tools, release 11.2, V11.2.142
Build cuda_11.2.r11.2/compiler.29558016_0'
# version1121='CUDA Version 11.2.146'
version1121='{
   "cuda" : {
      "name" : "CUDA SDK",
      "version" : "11.2.20210204"
   },
   "cuda_cudart" : {
      "name" : "CUDA Runtime (cudart)",
      "version" : "11.2.146"
   },
   "cuda_cuobjdump" : {
      "name" : "cuobjdump",
      "version" : "11.2.135"
   },
   "cuda_cupti" : {
      "name" : "CUPTI",
      "version" : "11.2.135"
   },
   "cuda_cuxxfilt" : {
      "name" : "CUDA cu++ filt",
      "version" : "11.2.135"
   },
   "cuda_demo_suite" : {
      "name" : "CUDA Demo Suite",
      "version" : "11.2.67"
   },
   "cuda_gdb" : {
      "name" : "CUDA GDB",
      "version" : "11.2.135"
   },
   "cuda_memcheck" : {
      "name" : "CUDA Memcheck",
      "version" : "11.2.135"
   },
   "cuda_nsight" : {
      "name" : "Nsight Eclipse Plugins",
      "version" : "11.2.135"
   },
   "cuda_nvcc" : {
      "name" : "CUDA NVCC",
      "version" : "11.2.142"
   },
   "cuda_nvdisasm" : {
      "name" : "CUDA nvdisasm",
      "version" : "11.2.135"
   },
   "cuda_nvml_dev" : {
      "name" : "CUDA NVML Headers",
      "version" : "11.2.67"
   },
   "cuda_nvprof" : {
      "name" : "CUDA nvprof",
      "version" : "11.2.135"
   },
   "cuda_nvprune" : {
      "name" : "CUDA nvprune",
      "version" : "11.2.135"
   },
   "cuda_nvrtc" : {
      "name" : "CUDA NVRTC",
      "version" : "11.2.142"
   },
   "cuda_nvtx" : {
      "name" : "CUDA NVTX",
      "version" : "11.2.67"
   },
   "cuda_nvvp" : {
      "name" : "CUDA NVVP",
      "version" : "11.2.135"
   },
   "cuda_samples" : {
      "name" : "CUDA Samples",
      "version" : "11.2.135"
   },
   "cuda_sanitizer_api" : {
      "name" : "CUDA Compute Sanitizer API",
      "version" : "11.2.135"
   },
   "libcublas" : {
      "name" : "CUDA cuBLAS",
      "version" : "11.4.1.1026"
   },
   "libcufft" : {
      "name" : "CUDA cuFFT",
      "version" : "10.4.0.135"
   },
   "libcurand" : {
      "name" : "CUDA cuRAND",
      "version" : "10.2.3.135"
   },
   "libcusolver" : {
      "name" : "CUDA cuSOLVER",
      "version" : "11.1.0.135"
   },
   "libcusparse" : {
      "name" : "CUDA cuSPARSE",
      "version" : "11.4.0.135"
   },
   "libnpp" : {
      "name" : "CUDA NPP",
      "version" : "11.3.2.139"
   },
   "libnvjpeg" : {
      "name" : "CUDA nvJPEG",
      "version" : "11.4.0.135"
   },
   "nsight_compute" : {
      "name" : "Nsight Compute",
      "version" : "2020.3.1.3"
   },
   "nsight_systems" : {
      "name" : "Nsight Systems",
      "version" : "2020.4.3.7"
   },
   "nvidia_driver" : {
      "name" : "NVIDIA Linux Driver",
      "version" : "460.32.03"
   }
}'

# 11.2.2
nvcc1122='nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Feb_14_21:12:58_PST_2021
Cuda compilation tools, release 11.2, V11.2.152
Build cuda_11.2.r11.2/compiler.29618528_0'
# version1122='CUDA Version 11.2.154'
version1122='{
   "cuda" : {
      "name" : "CUDA SDK",
      "version" : "11.2.20210226"
   },
   "cuda_cudart" : {
      "name" : "CUDA Runtime (cudart)",
      "version" : "11.2.152"
   },
   "cuda_cuobjdump" : {
      "name" : "cuobjdump",
      "version" : "11.2.152"
   },
   "cuda_cupti" : {
      "name" : "CUPTI",
      "version" : "11.2.152"
   },
   "cuda_cuxxfilt" : {
      "name" : "CUDA cu++ filt",
      "version" : "11.2.152"
   },
   "cuda_demo_suite" : {
      "name" : "CUDA Demo Suite",
      "version" : "11.2.152"
   },
   "cuda_gdb" : {
      "name" : "CUDA GDB",
      "version" : "11.2.152"
   },
   "cuda_memcheck" : {
      "name" : "CUDA Memcheck",
      "version" : "11.2.152"
   },
   "cuda_nsight" : {
      "name" : "Nsight Eclipse Plugins",
      "version" : "11.2.152"
   },
   "cuda_nvcc" : {
      "name" : "CUDA NVCC",
      "version" : "11.2.152"
   },
   "cuda_nvdisasm" : {
      "name" : "CUDA nvdisasm",
      "version" : "11.2.152"
   },
   "cuda_nvml_dev" : {
      "name" : "CUDA NVML Headers",
      "version" : "11.2.152"
   },
   "cuda_nvprof" : {
      "name" : "CUDA nvprof",
      "version" : "11.2.152"
   },
   "cuda_nvprune" : {
      "name" : "CUDA nvprune",
      "version" : "11.2.152"
   },
   "cuda_nvrtc" : {
      "name" : "CUDA NVRTC",
      "version" : "11.2.152"
   },
   "cuda_nvtx" : {
      "name" : "CUDA NVTX",
      "version" : "11.2.152"
   },
   "cuda_nvvp" : {
      "name" : "CUDA NVVP",
      "version" : "11.2.152"
   },
   "cuda_samples" : {
      "name" : "CUDA Samples",
      "version" : "11.2.152"
   },
   "cuda_sanitizer_api" : {
      "name" : "CUDA Compute Sanitizer API",
      "version" : "11.2.152"
   },
   "libcublas" : {
      "name" : "CUDA cuBLAS",
      "version" : "11.4.1.1043"
   },
   "libcufft" : {
      "name" : "CUDA cuFFT",
      "version" : "10.4.1.152"
   },
   "libcurand" : {
      "name" : "CUDA cuRAND",
      "version" : "10.2.3.152"
   },
   "libcusolver" : {
      "name" : "CUDA cuSOLVER",
      "version" : "11.1.0.152"
   },
   "libcusparse" : {
      "name" : "CUDA cuSPARSE",
      "version" : "11.4.1.1152"
   },
   "libnpp" : {
      "name" : "CUDA NPP",
      "version" : "11.3.2.152"
   },
   "libnvjpeg" : {
      "name" : "CUDA nvJPEG",
      "version" : "11.4.0.152"
   },
   "nsight_compute" : {
      "name" : "Nsight Compute",
      "version" : "2020.3.1.4"
   },
   "nsight_systems" : {
      "name" : "Nsight Systems",
      "version" : "2020.4.3.7"
   },
   "nvidia_driver" : {
      "name" : "NVIDIA Linux Driver",
      "version" : "460.32.03"
   }
}'

nvccs=("${nvcc1}" "${nvcc11}"
       "${nvcc2}" "${nvcc21}" "${nvcc22}" "${nvcc23}"
       "${nvcc3}" "${nvcc31}" "${nvcc32}"
       "${nvcc4}" "${nvcc41}" "${nvcc42}"
       "${nvcc5}" "${nvcc55}"
       "${nvcc6}" "${nvcc65}"
       "${nvcc7}" "${nvcc75}"
       "${nvcc8}" "${nvcc8ga2}"
       "${nvcc9}" "${nvcc91}" "${nvcc92}"
       "${nvcc10}" "${nvcc101}" "${nvcc101u1}" "${nvcc101u2}" "${nvcc102}"
       "${nvcc1101}" "${nvcc1102}" "${nvcc1103}" "${nvcc111}" "${nvcc1111}" "${nvcc112}" "${nvcc1121}" "${nvcc1122}")

nvccs_ans=(1.0 1.1
           2.0 2.1 2.2 2.3
           3.0 3.1 3.2
           4.0 4.1 4.2
           5.0 5.5.0
           6.0.1 6.5.12
           7.0.27 7.5.17
           8.0.44 8.0.61
           9.0.176 9.1.85 9.2.148
           10.0.130 10.1.105 10.1.168 10.1.243 10.2.89
           11.0.167 11.0.194 11.0.221 11.1.74 11.1.105 11.2.67 11.2.142 11.2.152)

versions_txt=("${version75}"
              "${version8}" "${version8ga}" "${version8ga2p2}"
              "${version9}" "${version9p1}" "${version9p2}" "${version9p3}" "${version9p4}" "${version91}" "${version91p1}" "${version91p2}" "${version91p3}" "${version92}" "${version92p1}"
              "${version10}" "${version10p1}" "${version101}" "${version101u1}" "${version101u2}" "${version102}"
              "${version1101}" "${version1102}" "${version1103}")
versions_txt_ans=(7.5.18
                  8.0.44 8.0.61 8.0.61.2
                  9.0.176 9.0.176.1 9.0.176.2 9.0.176.3 9.0.176.4 9.1.85 9.1.85.1 9.1.85.2 9.1.85.3 9.2.148 9.2.148.1
                  10.0.130 10.0.130.1 10.1.105 10.1.168 10.1.243 10.2.89
                  11.0.182 11.0.207 11.0.228)
versions_json=("${version1121}" "${version1122}")
versions_json_ans=(11.2.142 11.2.152)

device_query_string='deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 3 CUDA Capable device(s)

Device 0: "TITAN X (Pascal)"
  CUDA Driver Version / Runtime Version          11.1 / 7.5
  CUDA Capability Major/Minor version number:    6.1
  Total amount of global memory:                 12196 MBytes (12788498432 bytes)
MapSMtoCores for SM 6.1 is undefined.  Default to use 128 Cores/SM
MapSMtoCores for SM 6.1 is undefined.  Default to use 128 Cores/SM
  (28) Multiprocessors, (128) CUDA Cores/MP:     3584 CUDA Cores
  GPU Max Clock rate:                            1531 MHz (1.53 GHz)
  Memory Clock rate:                             5005 Mhz
  Memory Bus Width:                              384-bit
  L2 Cache Size:                                 3145728 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing (UVA):      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 4 / 0
  Compute Mode:
     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >

Device 1: "TITAN X (Pascal)"
  CUDA Driver Version / Runtime Version          11.1 / 7.5
  CUDA Capability Major/Minor version number:    6.1
  Total amount of global memory:                 12196 MBytes (12788498432 bytes)
MapSMtoCores for SM 6.1 is undefined.  Default to use 128 Cores/SM
MapSMtoCores for SM 6.1 is undefined.  Default to use 128 Cores/SM
  (28) Multiprocessors, (128) CUDA Cores/MP:     3584 CUDA Cores
  GPU Max Clock rate:                            1531 MHz (1.53 GHz)
  Memory Clock rate:                             5005 Mhz
  Memory Bus Width:                              384-bit
  L2 Cache Size:                                 3145728 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing (UVA):      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 131 / 0
  Compute Mode:
     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >

Device 2: "Quadro K600"
  CUDA Driver Version / Runtime Version          11.1 / 7.5
  CUDA Capability Major/Minor version number:    3.0
  Total amount of global memory:                 982 MBytes (1029570560 bytes)
  ( 1) Multiprocessors, (192) CUDA Cores/MP:     192 CUDA Cores
  GPU Max Clock rate:                            876 MHz (0.88 GHz)
  Memory Clock rate:                             891 Mhz
  Memory Bus Width:                              128-bit
  L2 Cache Size:                                 262144 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)
  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)
  Run time limit on kernels:                     Yes
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing (UVA):      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 3 / 0
  Compute Mode:
     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >
> Peer access from TITAN X (Pascal) (GPU0) -> TITAN X (Pascal) (GPU1) : No
> Peer access from TITAN X (Pascal) (GPU0) -> Quadro K600 (GPU2) : No
> Peer access from TITAN X (Pascal) (GPU1) -> TITAN X (Pascal) (GPU0) : No
> Peer access from TITAN X (Pascal) (GPU1) -> Quadro K600 (GPU2) : No
> Peer access from Quadro K600 (GPU2) -> TITAN X (Pascal) (GPU0) : No
> Peer access from Quadro K600 (GPU2) -> TITAN X (Pascal) (GPU1) : No

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.1, CUDA Runtime Version = 7.5, NumDevs = 3, Device0 = TITAN X (Pascal), Device1 = TITAN X (Pascal), Device2 = Quadro K600
Result = PASS'

nvidia_smi_old='Wed Mar 17 20:15:45 2021
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 00000000:04:00.0 Off |                    0 |
| N/A   32C    P0    59W / 149W |      0MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+'

nvidia_smi_new='Wed Mar 17 19:10:41 2021
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.45.01    Driver Version: 455.45.01    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro K600         Off  | 00000000:03:00.0 Off |                  N/A |
| 25%   48C    P8    N/A /  N/A |    182MiB /   981MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+'

nvidia_docker_gpu_info='
Driver version:          455.28
Supported CUDA version:  11.1

Device #0
  Model:         Quadro P600
  UUID:          GPU-d5023f30-5d7b-57b1-5dc2-012a1ade040a
  Path:          /dev/nvidia0
  Family:        Pascal
  Arch:          6.1
  Cores:         384
  Power:         N/A
  CPU Affinity:  NUMA node0
  PCI
    Bus ID:     0000:B5:00.0
    BAR1:       256 MiB
    Bandwidth:  15760 MB/s
  Memory
    ECC:        false
    Global:     1997 MiB
    Constant:   64 KiB
    Shared:     96 KiB
    L2 Cache:   512 KiB
    Bandwidth:  64160 MB/s
  Clocks
    Cores:        1620 MHz
    Memory:       2005 MHz
  P2P Available:  None

Device #1
  Model:         TITAN Xp
  UUID:          GPU-752e3f5a-ee57-13ea-aff9-4e785ce7a949
  Path:          /dev/nvidia1
  Family:        Pascal
  Arch:          6.1
  Cores:         3840
  Power:         250 W
  CPU Affinity:  NUMA node0
  PCI
    Bus ID:     0000:B6:00.0
    BAR1:       256 MiB
    Bandwidth:  15760 MB/s
  Memory
    ECC:        false
    Global:     12196 MiB
    Constant:   64 KiB
    Shared:     96 KiB
    L2 Cache:   3072 KiB
    Bandwidth:  547680 MB/s
  Clocks
    Cores:        1911 MHz
    Memory:       5705 MHz
  P2P Available:  None'

if ! command -v "${NVIDIA_SMI}" &> /dev/null; then
  skip_next_test
fi
begin_test "Cuda discover"
(
  setup_test

  discover_cuda_all

  (( ${#CUDA_CARD_FAMILIES[@]} > 0 ))
  (( ${#CUDA_CARD_ARCHES[@]} > 0 ))
  (( ${#CUDA_CARDS[@]} > 0 ))
  (( ${#CUDA_VERSIONS[@]} > 0 ))
)
end_test

begin_test "Cuda 7.5 test"
(
  setup_test

  # Setup
  CUDA_VERSION=7.5.01
  CUDA_CARD_ARCHES=(30 35 52 200)

  # Run code
  cuda_capabilities "${CUDA_VERSION}"
  suggested_architectures

  # Test it
  [ "${CUDA_VERSION}" = "7.5.01" ]
  assert_array_values CUDA_SUGGESTED_ARCHES 30 35 52
  assert_array_values CUDA_SUGGESTED_CODES 30 35 52
  [ "$(cmake_cuda_flags)" = "3.0 3.5 5.2 5.3+PTX" ]
)
end_test

begin_test "Cuda 9 test"
(
  setup_test

  # Setup
  CUDA_VERSION=9.0.01
  CUDA_CARD_ARCHES=(37 52 70)

  # Run code
  cuda_capabilities "${CUDA_VERSION}"
  suggested_architectures

  # Test it
  [ "${CUDA_VERSION}" = "9.0.01" ]
  assert_array_values CUDA_SUGGESTED_ARCHES 37 52 70
  assert_array_values CUDA_SUGGESTED_CODES 37 52 70
  [ "$(cmake_cuda_flags)" = "3.7 5.2 7.0" ]

  # Test the future flag
  CUDA_SUGGESTED_PTX+=(${CUDA_SUGGESTED_PTX+"${CUDA_SUGGESTED_PTX[@]}"} "${CUDA_FORWARD_PTX}")
  [ "$(cmake_cuda_flags)" = "3.7 5.2 7.0 7.0+PTX" ]
)
end_test

if [[ ${OSTYPE} != darwin* ]]; then
 skip_next_test
fi
begin_test "No Cuda on Darwin"
(
  setup_test

  . "${VSI_COMMON_DIR}/linux/cuda_info.bsh"

  [ -z "${CUDA_ARCHES+set}" ]
  [ -z "${CUDA_CODES+set}" ]
  [ -z "${CUDA_SUGGESTED_ARCHES+set}" ]
  [ -z "${CUDA_SUGGESTED_CODES+set}" ]
  [ -z "${CUDA_SUGGESTED_PTX+set}" ]
  [ -z "${CUDA_VERSIONS+set}" ]
  [ -z "${CUDA_VERSION+set}" ]
  [ -z "${CUDA_FORWARD_PTX+set}" ]
)
end_test

begin_test "Use nvidia-smi to get cuda version"
(
  setup_test

  function nvidia-smi()
  {
    echo "${nvidia_smi_old}"
  }

  [ "$(nvidia_smi_cuda_version)" == "" ]

  function nvidiasmi2()
  {
    echo "${nvidia_smi_new}"
  }

  [ "$(NVIDIA_SMI=nvidiasmi2 nvidia_smi_cuda_version)" == "11.1" ]
)
end_test

begin_test "Use deviceQuery to get cuda version"
(
  setup_test

  function deviceQuery2()
  {
    echo "${device_query_string}"
  }

  function deviceQuery(){ return 1;}

  not device_query_cuda_capability

  DEVICE_QUERY=deviceQuery2 device_query_cuda_capability

  assert_array_values CUDA_CARD_ARCHES 6.1 6.1 3.0
  assert_array_values CUDA_CARDS "TITAN X (Pascal)" "TITAN X (Pascal)" "Quadro K600"
)
end_test

begin_test "Use nvidia-docker plugin to get capabilities"
(
  setup_test

  function wget()
  {
    echo "${nvidia_docker_gpu_info}"

    echo "${@}" > "${TESTDIR}/args.txt"
  }

  nvidia_docker_plugin_cuda_capability

  assert_array_values CUDA_CARD_FAMILIES Pascal Pascal
  assert_array_values CUDA_CARD_ARCHES 6.1 6.1
  assert_array_values CUDA_CARDS "Quadro P600" "TITAN Xp"

  [[ $(cat "${TESTDIR}/args.txt") = http://localhost:3476/gpu/info* ]]

  NV_HOST=http://foo.bar:1234
  nvidia_docker_plugin_cuda_capability
  [[ $(cat "${TESTDIR}/args.txt") = http://foo.bar:1234/gpu/info* ]]
)
end_test

begin_test "Use version.txt to get version"
(
  setup_test

  # Out of order example
  [ "$(version_txt_cuda_version <(echo $'CUDA Version 9.0.176\nCUDA Patch Version 9.0.176.2\nCUDA Patch Version 9.0.176.1'))" = "9.0.176.2" ]

  # Test data
  for i in "${!versions_txt[@]}"; do
    [ "$(version_txt_cuda_version <<< "${versions_txt[i]}")" = "${versions_txt_ans[i]}" ]
  done
)
end_test

begin_test "Use version.json to get version"
(
  setup_test

  # Test data
  for i in "${!versions_json[@]}"; do
    [ "$(version_json_cuda_version <<< "${versions_json[i]}")" = "${versions_json_ans[i]}" ]
  done
)
end_test

begin_test "Get nvcc version"
(
  setup_test

  function nvcc(){ echo "${nvcc_string}";}

  for i in "${!nvccs[@]}"; do
    nvcc_string="${nvccs[i]}"
    [ "$(get_nvcc_version)" = "${nvccs_ans[i]}" ]
  done

  function nvcc2(){ echo "${nvcc1}";}
  [ "$(NVCC=nvcc2 get_nvcc_version)" = "1.0" ]
)
end_test

begin_test "Discover cuda versions"
(
  setup_test
  function nvcc(){ :;}
  function get_nvcc_version(){ :;}
  function version_txt_cuda_version(){ :;}
  function version_json_cuda_version(){ :;}
  function nvidia-smi(){ :;}

  function nvidia_smi_cuda_version(){ echo "11.2";}
  discover_cuda_versions
  [[ ${CUDA_VERSIONS[*]} = *11.2* ]] || false

  function get_nvcc_version(){ echo "10.2.3";}
  discover_cuda_versions
  [[ ${CUDA_VERSIONS[*]} = *10.2.3* ]] || false
)
end_test

begin_test "Cuda Arch to Cuda Family"
(
  setup_test

  CUDA_CARD_ARCHES=()
  cuda_arch_to_cuda_family
  assert_array_values CUDA_CARD_FAMILIES

  CUDA_CARD_ARCHES=(6.1)
  cuda_arch_to_cuda_family
  assert_array_values CUDA_CARD_FAMILIES Pascal

  CUDA_CARD_ARCHES=(6.1 3.0)
  cuda_arch_to_cuda_family
  assert_array_values CUDA_CARD_FAMILIES Pascal Kepler

  CUDA_CARD_ARCHES=(6.1 6.1 8.0)
  cuda_arch_to_cuda_family
  assert_array_values CUDA_CARD_FAMILIES Pascal Pascal Ampere
)
end_test

begin_test "Discover Cuda Info"
(
  setup_test

  DEVICE_QUERY=--error

  function __nvidia_docker_is_running()
  {
    return 1
  }

  ans="deviceQuery not found and nvidia-docker v1 plugin not running"
  [[ $(discover_cuda_info) = ${ans}* ]] || false

  function __nvidia_docker_is_running()
  {
    return 0
  }

  function nvidia_docker_plugin_cuda_capability()
  {
    echo 111
  }
  [ "$(discover_cuda_info)" = "111" ]

  unset DEVICE_QUERY
  function device_query()
  {
    return
  }

  function device_query_cuda_capability()
  {
    return 1
  }
  [ "$(discover_cuda_info)" = "111" ]

  function device_query_cuda_capability()
  {
    echo "222"
  }
  [ "$(discover_cuda_info)" = "222" ]
)
end_test
