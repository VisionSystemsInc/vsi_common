================
CUDA Information
================

.. default-domain:: bash

.. file:: cuda_info.bsh

Determine easy to use capabilities for ``CUDA`` devices

There are many versions of ``CUDA``, ``CUDA`` card architectures, etc... Knowing how to compile for a specific card is hard enough, but it's very difficult to know what the right architectures are for your specific card and what the limitations are based on your version of ``CUDA/NVIDIA`` driver, etc. This script should help determine what versions you have and suggest what architectures to use. This is good enough for an automated solution to get up and running, but these suggestions are not absolute. You may find a fine-tuned configuration that works better on a case-by-case basis.

.. envvar:: CUDA_VERSION

The version of ``CUDA`` being used

:file:`cuda_info.bsh` will attempt to discover the ``CUDA`` Development Kit in commonly known locations, and accumulate a list of all discovered CDKs in the sorted array CUDA_VERSIONS. Then, the highest capable version of ``CUDA`` is picked and set to :envvar:`CUDA_VERSION`.

:envvar:`CUDA_VERSION` can optionally be set to a specific version (e.g. "7.5.13"), in which case other ``CUDA`` versions will not be discovered and ``CUDA_VERSIONS`` will not be populated.

.. note::
  Currently, CDKs are discovered by checking the system PATH and /usr/local/cuda*/bin/ directories for the nvcc executable. More paths should be added to this file as they become necessary.

.. function:: discover_cuda_versions

:Output: ``CUDA_VERSIONS`` - List of ``CUDA`` versions found

Find ``CUDA`` development kits

.. note::
  Will not work on macosx if mac have nvidia and two or more versions of cuda
  installed. Seems unlikely

.. envvar:: CUDA_DISCOVER

:Parameter: ``CUDA_DISCOVER`` - Default is disabled, set to ``1`` to enable.

Flag to enable the discovery of CUDA cards and capabilities

Because the ``CUDA`` card discovery can be expensive (milliseconds on some computers, hundreds on others), it is disabled by default.

There are two methods for CUDA device discovery (in order):
 1. Using deviceQuery (available here https://goo.gl/ocBgPU)

  * looks for ${DEVICE_QUERY-deviceQuery} on the PATH

 2. Using the nvidia-docker-plugin to get and parse GPU information

  * discovered using either ``NV_HOST`` or checking to see if nvidia-docker-plugin is running locally using pgrep or ps

When running in a docker, deviceQuery is the preferred method. ``NV_HOST`` could be used, but that involves telling the docker the IP of the host, or using a shared network mode in order to use localhost (which is not recommended for production). Attempting to discover nvidia-docker-plugin will not work in a docker.

.. envvar:: CUDA_CARDS

List of ``CUDA`` devices found on the computer

An array of all the ``CUDA`` cards discovered. The only way to manually override this would be to disable :envvar:`CUDA_DISCOVER`, but that was not the intended use.

.. envvar:: CUDA_CARD_ARCHES

List of ``CUDA`` card architectures

An array of all the architectures the ``CUDA`` cards discovered. The only way to manually override this would be to disable :envvar:`CUDA_DISCOVER`, but that was not the intended use.

.. envvar:: CUDA_CARD_FAMILIES

List of ``CUDA`` card family names

An array of all the family names of the ``CUDA`` cards discovered. The only way to manually override this would be to disable :envvar:`CUDA_DISCOVER`, but that was not the intended use.

.. note::
  If deviceQuery is not used, then an internal lookup table is used, but only supports Tesla, Fermi, Kepler, Maxwell, Pascal, and Volta. Additional family names need to be added as they are released.

.. function:: discover_cuda_info

:Output: * :envvar:`CUDA_CARDS` - List of all ``CUDA`` capable devices
         * :envvar:`CUDA_CARD_ARCHES` - Matching list of ``CUDA`` real architectures
         * :envvar:`CUDA_CARD_FAMILIES` - Matching list of ``CUDA`` families

Get ``CUDA`` info about each card

.. envvar:: DEVICE_QUERY

Name of the device query executable

.. rubric:: Usage

Optional override for the name of the executable for device query. Device query is one of the sample programs in the ``CUDA`` Development Kit that prints out useful information about the connected ``CUDA`` devices.

:envvar:`DEVICE_QUERY` defaults to "deviceQuery" and must either be on the PATH or be an absolute path.

The deviceQuery executable is compiled from the source code typically found the in /usr/local/cuda/samples/1_Utilities/deviceQuery/ directory, but can be downloaded precompiled for Linux from https://goo.gl/equvX3

.. envvar:: CUDA_ARCHES

List of ``CUDA`` "virtual" instruction sets supported by ``CUDA``

Every version of ``CUDA`` (nvcc) has a set of "virtual" compute_xx architectures (ISAs) that it can build against when compiling code for "real" sm_xx architectures.

This array contains the list of the compute (virtual) architectures supported by the :envvar:`CUDA_VERSION` version of ``CUDA`` as an array of two digit numbers.

.. rubric:: Example

.. code-block:: bash

    $ echo "${CUDA_ARCHES[@]}"
    20 30 32 35 37 50 52 53 60 61 62

  Adding the periods to the architecture version number:

  y=()
  for x in ${CUDA_ARCHES[@]+"${CUDA_ARCHES[@]}"}; do
    y+=("${x:0:${#x}-1}.${x:${#x}-1:1}")
  done

  $ echo "${y[@]}"
  2.0 3.0 3.2 3.5 3.7 5.0 5.2 5.3 6.0 6.1 6.2

.. seealso::
  :envvar:`CUDA_DEPRECATED`

.. envvar:: CUDA_CODES

List of ``CUDA`` "real" instruction sets supported by ``CUDA``

Every version of ``CUDA`` (nvcc) has a set of "real" sm_xx architectures that that it can assemble native (``CUDA`` binary) code for.

This array contains a list of the sm architectures supported by the :envvar:`CUDA_VERSION` version of ``CUDA`` as an array of two digit numbers.

.. rubric:: Example

.. code-block:: bash

    $ echo "${CUDA_CODES[@]}"
    20 21 30 32 35 37 50 52 53 60 61 62

.. seealso::
  :envvar:`CUDA_DEPRECATED`

.. envvar:: CUDA_MINIMAL_DRIVER_VERSION

Required version of NVIDIA driver

Every version of ``CUDA`` has a minimal version of the NVIDIA graphics-card driver that must be installed in order to support that version of ``CUDA``. This is largely undocumented, despite being obviously important. This variable is set to the minimum required version of the NVIDIA driver for the :envvar:`CUDA_VERSION` version of ``CUDA``, as best as we've been able to determine.

.. envvar:: CUDA_DEPRECATED

List of deprecated instruction sets supported by ``CUDA``

Some versions of ``CUDA`` support old instruction sets, but print a deprecated warning. For those versions of ``CUDA``, a :envvar:`CUDA_DEPRECATED` array is defined to list the two digit architectures that are supported yet deprecated in the :envvar:`CUDA_VERSION` version of ``CUDA``.

.. function:: cuda_capabilities

:Output: * :envvar:`CUDA_ARCHES` - Supported ``CUDA`` virtual architectures (compute_xx)
         * :envvar:`CUDA_CODES` - Supported ``CUDA`` real architectures (sm_xx)
         * :envvar:`CUDA_MINIMAL_DRIVER_VERSION` - Minimal NVIDIA driver version needed for :envvar:`CUDA_VERSION` version of graphics-card driver
         * [:envvar:`CUDA_DEPRECATED`] - List of deprecated (yet working) architectures.

Determine compiler capabilities for specific CDK

.. envvar:: CUDA_SUGGESTED_ARCHES

Suggested "virtual" architectures to compile for

Instead of compiling for every architecture that the :envvar:`CUDA_VERSION` version of ``CUDA`` supports, :envvar:`CUDA_SUGGESTED_ARCHES` is the intersection between :envvar:`CUDA_CARD_ARCHES` and :envvar:`CUDA_ARCHES` so that you compile only for your cards.

.. envvar:: CUDA_SUGGESTED_CODES

Suggested "real" architectures to compile for

Instead of compiling for every architecture that the :envvar:`CUDA_VERSION` version of ``CUDA`` supports, :envvar:`CUDA_SUGGESTED_CODES` is the intersection between ``CUDA_CARD_CODES`` and :envvar:`CUDA_CODES` so that you compile only for your cards.

.. envvar:: CUDA_SUGGESTED_PTX

Suggested PTX architectures to compile for

If your graphics card is too new for the :envvar:`CUDA_VERSION` version of ``CUDA``, you will need to compile to a pure virtual architecture (by embedding PTX code in the fatbinary) in order to use it. That way, the real architecture can be JIT (Just-In-Time) compiled for at runtime.

:envvar:`CUDA_SUGGESTED_PTX` identifies the PTX architectures you need to run on newer (unsupported) cards. You can choose to add them to your builds.

.. envvar:: CUDA_FORWARD_PTX

PTX arch for newer ``CUDA`` cards

In situations where you are making portable fatbinaries, you should compile for every architecture. However, in order to future proof your fatbin for architectures newer than your current version of ``CUDA`` supports, you will need to compile to a pure virtual architecture using the PTX feature so that the real architecture can be JIT (Just-In-Time) compiled.

:envvar:`CUDA_FORWARD_PTX` identifies the fullest featured PTX architecture so that you can choose to add this to your builds.

.. function:: suggested_architectures

:Output: * :envvar:`CUDA_SUGGESTED_ARCHES` - Suggested virtual architectures for your cards
         * :envvar:`CUDA_SUGGESTED_CODES` - Suggested real architectures for your cards
         * :envvar:`CUDA_SUGGESTED_PTX` - Suggested PTX for your cards
         * :envvar:`CUDA_FORWARD_PTX` - Potential forward compatibility PTX to compile for cards newer than your current ``CUDA`` supports

Calculate suggested architectures

.. function:: cmake_cuda_flags

:Parameters: * :envvar:`CUDA_SUGGESTED_ARCHES` - List of virtual architectures to compile
             * :envvar:`CUDA_SUGGESTED_CODES` - Matching list of real architectures to compile
             * [:envvar:`CUDA_SUGGESTED_PTX`] - Optional list of PTX architectures to compile
:Output: *stdout* - echoes out the value of the target_CUDA_architectures

Generate ``CUDA`` flags for CMake

Modern CMake installs include a FindCUDA.cmake script which calls the select_compute_arch.cmake script (https://goo.gl/uZvAjR). It uses a limited version of the tables that :file:`cuda_info.bsh` uses and is prone to being out of date.

This function will calculate the suggested value of target_CUDA_architectures for CMake's:

  FindCUDA.cmake:select_compute_arch.cmake:CUDA_SELECT_NVCC_ARCH_FLAGS

You will need to find where this is used and set the variable accordingly.

.. rubric:: Example

For example, PyTorch's CMake contains:

.. code-block:: bash

  CUDA_SELECT_NVCC_ARCH_FLAGS(NVCC_FLAGS_EXTRA $ENV{TORCH_CUDA_ARCH_LIST})

Setting the environment variable ``TORCH_CUDA_ARCH_LIST`` to the output of :func:`cmake_cuda_flags` will result in using the desired ``CUDA`` architecture and code versions.

To add the :envvar:`CUDA_FORWARD_PTX`, run:

.. code-block:: bash

  CUDA_SUGGESTED_PTX+=(${CUDA_FORWARD_PTX})

before calling :func:`cmake_cuda_flags`

