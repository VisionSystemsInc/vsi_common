#!/usr/bin/env false
# Source this file

if [[ $- != *i* ]]; then
  source_once &> /dev/null && return 0
fi

#*# linux/cuda_info

#**
# ================
# CUDA Information
# ================
#
# .. default-domain:: bash
#
# .. file:: cuda_info.bsh
#
# Determine easy to use capabilities for ``CUDA`` devices
#
# There are many versions of ``CUDA``, ``CUDA`` card architectures, etc... Knowing how to compile for a specific card is hard enough, but it's very difficult to know what the right architectures are for your specific card and what the limitations are based on your version of ``CUDA/NVIDIA`` driver, etc. This script should help determine what versions you have and suggest what architectures to use. This is good enough for an automated solution to get up and running, but these suggestions are not absolute. You may find a fine-tuned configuration that works better on a case-by-case basis.
#**

#**
# .. envvar:: CUDA_VERSION
#
# The version of ``CUDA`` being used
#
# :file:`cuda_info.bsh` will attempt to discover the ``CUDA`` Development Kit in commonly known locations, and accumulate a list of all discovered CDKs in the sorted array CUDA_VERSIONS. Then, the highest capable version of ``CUDA`` is picked and set to :envvar:`CUDA_VERSION`.
#
# :envvar:`CUDA_VERSION` can optionally be set to a specific version (e.g. "7.5.13"), in which case other ``CUDA`` versions will not be discovered and ``CUDA_VERSIONS`` will not be populated.
#
# .. note::
#   Currently, CDKs are discovered by checking the system PATH and /usr/local/cuda*/bin/ directories for the nvcc executable. More paths should be added to this file as they become necessary.
#**

#**
# .. function:: discover_cuda_versions
#
# :Output: ``CUDA_VERSIONS`` - List of ``CUDA`` versions found
#
# Find ``CUDA`` development kits
#
# .. note::
#   Will not work on macosx if mac have nvidia and two or more versions of cuda
#   installed. Seems unlikely
#**
function discover_cuda_versions()
{
  CUDA_VERSIONS=()
  local IFS=$'\n' # Handle spaces, tabs, but not newlines in the paths
  local version
  for version in $(command -v nvcc) /usr/local/cuda*/bin/nvcc; do
    CUDA_VERSIONS+=($("${version}" --version | \awk 'END{print substr($6, 2)}'))
  done 2>/dev/null

  if [ "${#CUDA_VERSIONS[@]}" = "0" ] && command -v "${NVIDIA_SMI-nvidia-smi}" &> /dev/null; then
    echo "No CUDA found: Determining max supported CUDA instead" >&2
    CUDA_VERSIONS=("$(nvidia-smi | sed -nE '/CUDA Version:/{s|.*CUDA Version: *([0-9.]*).*|\1|;p;q}')")
  fi

  # Prevent macos from crashing. Not sure why this is new. Might be darling
  if [ ${#CUDA_VERSIONS[@]} -gt 1 ]; then
    CUDA_VERSIONS=($(sort -uV <<< ${CUDA_VERSIONS+"${CUDA_VERSIONS[*]}"}))
  fi
  # Get the highest cuda level
  CUDA_VERSION=${CUDA_VERSIONS+"${CUDA_VERSIONS[${#CUDA_VERSIONS[@]}-1]}"}
}

#**
# .. envvar:: CUDA_DISCOVER
#
# :Parameter: ``CUDA_DISCOVER`` - Default is disabled, set to ``1`` to enable.
#
# Flag to enable the discovery of CUDA cards and capabilities
#
# Because the ``CUDA`` card discovery can be expensive (milliseconds on some computers, hundreds on others), it is disabled by default.
#
# There are two methods for CUDA device discovery (in order):
#  1. Using deviceQuery (available here https://goo.gl/ocBgPU)
#
#   * looks for ${DEVICE_QUERY-deviceQuery} on the PATH
#
#  2. Using the nvidia-docker-plugin to get and parse GPU information
#
#   * discovered using either ``NV_HOST`` or checking to see if nvidia-docker-plugin is running locally using pgrep or ps
#
# When running in a docker, deviceQuery is the preferred method. ``NV_HOST`` could be used, but that involves telling the docker the IP of the host, or using a shared network mode in order to use localhost (which is not recommended for production). Attempting to discover nvidia-docker-plugin will not work in a docker.
#**

#**
# .. envvar:: CUDA_CARDS
#
# List of ``CUDA`` devices found on the computer
#
# An array of all the ``CUDA`` cards discovered. The only way to manually override this would be to disable :envvar:`CUDA_DISCOVER`, but that was not the intended use.
#**

#**
# .. envvar:: CUDA_CARD_ARCHES
#
# List of ``CUDA`` card architectures
#
# An array of all the architectures the ``CUDA`` cards discovered. The only way to manually override this would be to disable :envvar:`CUDA_DISCOVER`, but that was not the intended use.
#**

#**
# .. envvar:: CUDA_CARD_FAMILIES
#
# List of ``CUDA`` card family names
#
# An array of all the family names of the ``CUDA`` cards discovered. The only way to manually override this would be to disable :envvar:`CUDA_DISCOVER`, but that was not the intended use.
#
# .. note::
#   If deviceQuery is not used, then an internal lookup table is used, but only supports Tesla, Fermi, Kepler, Maxwell, Pascal, and Volta. Additional family names need to be added as they are released.
#**

#**
# .. function:: discover_cuda_info
#
# :Output: * :envvar:`CUDA_CARDS` - List of all ``CUDA`` capable devices
#          * :envvar:`CUDA_CARD_ARCHES` - Matching list of ``CUDA`` real architectures
#          * :envvar:`CUDA_CARD_FAMILIES` - Matching list of ``CUDA`` families
#
# Get ``CUDA`` info about each card
#**

function discover_cuda_info()
{
  if command -v pgrep &> /dev/null; then
    function nvidia_docker_is_running()
    {
      \pgrep -f "${1}" &> /dev/null
      return $?
    }
  else
    function nvidia_docker_is_running()
    {
      [ $(\ps -ef | \grep "${1}" | \wc -l) -gt 1 ]
      return $?
    }
  fi

#**
# .. envvar:: DEVICE_QUERY
#
# Name of the device query executable
#
# .. rubric:: Usage
#
# Optional override for the name of the executable for device query. Device query is one of the sample programs in the ``CUDA`` Development Kit that prints out useful information about the connected ``CUDA`` devices.
#
# :envvar:`DEVICE_QUERY` defaults to "deviceQuery" and must either be on the PATH or be an absolute path.
#
# The deviceQuery executable is compiled from the source code typically found the in /usr/local/cuda/samples/1_Utilities/deviceQuery/ directory, but can be downloaded precompiled for Linux from https://goo.gl/equvX3
#**

  local IFS="${IFS}"
  local OLD_IFS="${IFS}"

  CUDA_CARD_FAMILIES=()

  # Attempt to use deviceQuery
  if command -v "${DEVICE_QUERY-deviceQuery}" &> /dev/null; then
    local card_info cuda_card_arches cuda_card_families
    local x y

    # deviceQuery may fail, for example, if running without nvidia-docker or if
    # the CUDA driver version is insufficient for CUDA runtime version
    if card_info="$(${DEVICE_QUERY-deviceQuery} | \grep -E "CUDA Capability Major/Minor version number|^Device")"; then
      CUDA_CARD_ARCHES=($(echo "${card_info}" | \grep "CUDA Capability Major/Minor version number" | \awk '{print $NF}'))
      IFS=$'\n'
      CUDA_CARDS=($(echo "${card_info}" | \grep ^Device | \awk '{$1=$2=""; $0=$0; $1=$1}1' | \sed 's|"||g'))
      IFS="${OLD_IFS}"
      # Currently these two arrays can't have spaces, if they do, the awk will need to be updated
      cuda_card_arches=(1 2 3 5 6 7 7.5) # Lowest possible version number, put in ascending order
      cuda_card_families=(Tesla Fermi Kepler Maxwell Pascal Volta Turing) # Matching Family name
      for x in ${CUDA_CARD_ARCHES+"${CUDA_CARD_ARCHES[@]}"}; do
        CUDA_CARD_FAMILIES+=("$(awk '
        BEGIN {
          # Split the arches array
          version[0]=""
          a="'"${cuda_card_arches[*]}"'"
          n=split(a, version, " ")

          # Split the family array
          family[0]=""
          a="'"${cuda_card_families[*]}"'"
          split(a, family, " ")

          # loop through all the versions
          for(j = n; j > 0; j--)
          {
            # if it matches
            if ('"${x}"' >= version[j])
            {
              # Print it out
              print family[j]
              exit(0)
            }
          }
          # Default behavior
          print "Unknown family"
        }')")
      done
    fi
  # Else attempt to use the nvidia-docker daemon
  elif nvidia_docker_is_running nvidia-docker-plugin || declare -p NV_HOST &> /dev/null; then
    local download_cmd
    local card_info
    # Warning not in cuda order. Oh well
    if command -v curl &> /dev/null; then
      download_cmd="curl -s"
    else
      download_cmd="wget -qO-"
    fi

    card_info="$($download_cmd ${NV_HOST-http://localhost:3476}/gpu/info)"

    CUDA_CARD_FAMILIES=($(echo "${card_info}" | \grep Family: | \awk '{print $NF}'))
    CUDA_CARD_ARCHES=($(echo "${card_info}" | \grep Arch: | \awk '{print $NF}'))
    IFS=$'\n'
    CUDA_CARDS=($(echo "${card_info}" | \grep Model: | \awk '{$1=""; $0=$0; $1=$1}1'))
    IFS="${OLD_IFS}"
  else
    echo "deviceQuery not found and nvidia-docker v1 plugin not running"
    echo "deviceQuery can be downloaded from https://www.vsi-ri.com/bin/deviceQuery60"
    echo "or https://goo.gl/equvX3"
  fi
  CUDA_CARD_ARCHES=(${CUDA_CARD_ARCHES+"${CUDA_CARD_ARCHES[@]/./}"})
}

#**
# .. envvar:: CUDA_ARCHES
#
# List of ``CUDA`` "virtual" instruction sets supported by ``CUDA``
#
# Every version of ``CUDA`` (nvcc) has a set of "virtual" compute_xx architectures (ISAs) that it can build against when compiling code for "real" sm_xx architectures.
#
# This array contains the list of the compute (virtual) architectures supported by the :envvar:`CUDA_VERSION` version of ``CUDA`` as an array of two digit numbers.
#
# .. rubric:: Example
#
# .. code-block:: bash
#
#     $ echo "${CUDA_ARCHES[@]}"
#     20 30 32 35 37 50 52 53 60 61 62
#
#   Adding the periods to the architecture version number:
#
#   y=()
#   for x in ${CUDA_ARCHES+"${CUDA_ARCHES[@]}"}; do
#     y+=("${x:0:${#x}-1}.${x:${#x}-1:1}")
#   done
#
#   $ echo "${y[@]}"
#   2.0 3.0 3.2 3.5 3.7 5.0 5.2 5.3 6.0 6.1 6.2
#
# .. seealso::
#   :envvar:`CUDA_DEPRECATED`
#**

#**
# .. envvar:: CUDA_CODES
#
# List of ``CUDA`` "real" instruction sets supported by ``CUDA``
#
# Every version of ``CUDA`` (nvcc) has a set of "real" sm_xx architectures that that it can assemble native (``CUDA`` binary) code for.
#
# This array contains a list of the sm architectures supported by the :envvar:`CUDA_VERSION` version of ``CUDA`` as an array of two digit numbers.
#
# .. rubric:: Example
#
# .. code-block:: bash
#
#     $ echo "${CUDA_CODES[@]}"
#     20 21 30 32 35 37 50 52 53 60 61 62
#
# .. seealso::
#   :envvar:`CUDA_DEPRECATED`
#**

#**
# .. envvar:: CUDA_MINIMAL_DRIVER_VERSION
#
# Required version of NVIDIA driver
#
# Every version of ``CUDA`` has a minimal version of the NVIDIA graphics-card driver that must be installed in order to support that version of ``CUDA``. This is largely undocumented, despite being obviously important. This variable is set to the minimum required version of the NVIDIA driver for the :envvar:`CUDA_VERSION` version of ``CUDA``, as best as we've been able to determine.
#**

#**
# .. envvar:: CUDA_DEPRECATED
#
# List of deprecated instruction sets supported by ``CUDA``
#
# Some versions of ``CUDA`` support old instruction sets, but print a deprecated warning. For those versions of ``CUDA``, a :envvar:`CUDA_DEPRECATED` array is defined to list the two digit architectures that are supported yet deprecated in the :envvar:`CUDA_VERSION` version of ``CUDA``.
#**

#**
# .. function:: cuda_capabilities
#
# :Output: * :envvar:`CUDA_ARCHES` - Supported ``CUDA`` virtual architectures (compute_xx)
#          * :envvar:`CUDA_CODES` - Supported ``CUDA`` real architectures (sm_xx)
#          * :envvar:`CUDA_MINIMAL_DRIVER_VERSION` - Minimal NVIDIA driver version needed for :envvar:`CUDA_VERSION` version of graphics-card driver
#          * [:envvar:`CUDA_DEPRECATED`] - List of deprecated (yet working) architectures.
#
# Determine compiler capabilities for specific CDK
#**
function cuda_capabilities()
{
  # This is the most complete list of compute and sm architectures supported by
  # CUDA version that I know of. It was created using strings on nvcc from each
  # version of CUDA. Documentation, stackoverflow, and random blogs often miss
  # at least one piece of information and is not this complete nor will it
  # verify this table.

  # This seems to be updated regularly
  # https://stackoverflow.com/a/30820690/4166604
  case ${CUDA_VERSION} in
    1.0*)
      CUDA_ARCHES=(10 11)
      CUDA_CODES=(10 11)
      if [ "${OS-}" == "Windows_NT" ]; then
        CUDA_MINIMAL_DRIVER_VERSION=162.01 #~
      else
        CUDA_MINIMAL_DRIVER_VERSION=100.14 #~
      fi
      ;;
    1.1*)
      CUDA_ARCHES=(10 11)
      CUDA_CODES=(10 11)
      CUDA_MINIMAL_DRIVER_VERSION=169.01
      ;;
    2.0*)
      CUDA_ARCHES=(10 11 12 13)
      CUDA_CODES=(10 11 12 13)
      CUDA_MINIMAL_DRIVER_VERSION=177.70 #~
      ;;
    2.1*)
      CUDA_ARCHES=(10 11 12 13)
      CUDA_CODES=(10 11 12 13)
      CUDA_MINIMAL_DRIVER_VERSION=180.22 #~
      ;;
    2.2*)
      CUDA_ARCHES=(10 11 12 13)
      CUDA_CODES=(10 11 12 13)
      CUDA_MINIMAL_DRIVER_VERSION=185.18.14 #~
      ;;
    2.3*)
      CUDA_ARCHES=(10 11 12 13)
      CUDA_CODES=(10 11 12 13)
      CUDA_MINIMAL_DRIVER_VERSION=190.53 #~
      ;;
    3.0*)
      CUDA_ARCHES=(10 11 12 13 20)
      CUDA_CODES=(10 11 12 13 20)
      CUDA_MINIMAL_DRIVER_VERSION=195.36.15
      ;;
    3.1*)
      CUDA_ARCHES=(10 11 12 13 20 30)
      CUDA_CODES=(10 11 12 13 20 21 22 23 30)
      CUDA_MINIMAL_DRIVER_VERSION=256.40
      ;;
    3.2*) #.16
      CUDA_ARCHES=(10 11 12 13 20)
      CUDA_CODES=(10 11 12 13 20 21)
      CUDA_MINIMAL_DRIVER_VERSION=260.19.26
      ;;
    4.0*) #.17
      CUDA_ARCHES=(10 11 12 13 20)
      CUDA_CODES=(10 11 12 13 20 21 22 23)
      CUDA_MINIMAL_DRIVER_VERSION=270.41.19
      ;;
    4.1*) #.28
      CUDA_ARCHES=(10 11 12 13 20)
      CUDA_CODES=(10 11 12 13 20 21)
      CUDA_MINIMAL_DRIVER_VERSION=285.05.33
      ;;
    4.2*) #.9
      CUDA_ARCHES=(10 11 12 13 20 30)
      CUDA_CODES=(10 11 12 13 20 21 30)
      CUDA_MINIMAL_DRIVER_VERSION=295.41
      ;;
    5.0*) #.35
      CUDA_ARCHES=(10 11 12 13 20 30 35)
      CUDA_CODES=(10 11 12 13 20 21 30 35)
      CUDA_MINIMAL_DRIVER_VERSION=304
      ;;
    5.5*) #.22
      CUDA_ARCHES=(10 11 12 13 20 30 35)
      CUDA_CODES=(10 11 12 13 20 21 30 35)
      CUDA_MINIMAL_DRIVER_VERSION=319
      ;;
    6.0*) #.1
      CUDA_ARCHES=(10 11 12 13 20 30 32 35 50)
      CUDA_CODES=(10 11 12 13 20 21 30 32 35 50)
      CUDA_MINIMAL_DRIVER_VERSION=331
      CUDA_DEPRECATED=(10)
      ;;
    6.5*) #.12
      CUDA_ARCHES=(11 12 13 20 30 32 35 37 50 52)
      CUDA_CODES=(11 12 13 20 21 30 32 35 37 50 52)
      CUDA_MINIMAL_DRIVER_VERSION=340
      CUDA_DEPRECATED=(11 12 13)
      ;;
    7.0*) #.27
      CUDA_ARCHES=(20 30 32 35 37 50 52 53)
      CUDA_CODES=(20 21 30 32 35 37 50 52 53)
      CUDA_MINIMAL_DRIVER_VERSION=346
      ;;
    7.5*) #.17
      CUDA_ARCHES=(20 30 32 35 37 50 52 53)
      CUDA_CODES=(20 21 30 32 35 37 50 52 53)
      CUDA_MINIMAL_DRIVER_VERSION=352
      ;;
    8*) #.0.61
      CUDA_ARCHES=(20 30 32 35 37 50 52 53 60 61 62)
      CUDA_CODES=(20 21 30 32 35 37 50 52 53 60 61 62)
      CUDA_MINIMAL_DRIVER_VERSION=361
      CUDA_DEPRECATED=(20 21)
      ;;
    9.0*) #RC2 .103 and 0.176, and
      CUDA_ARCHES=(30 32 35 37 50 52 53 60 61 62 70)
      CUDA_CODES=(30 32 35 37 50 52 53 60 61 62 70)
      CUDA_MINIMAL_DRIVER_VERSION=384 #.59
      #https://devtalk.nvidia.com/default/topic/1023719/cuda-setup-and-installation/-solved-cuda-9-0rc-and-nvidia-384-69-but-driver-version-is-insufficient-for-cuda-runtime-version/
      ;;
    9.1*) #.85
      CUDA_ARCHES=(30 32 35 37 50 52 53 60 61 62 70 72)
      CUDA_CODES=(30 32 35 37 50 52 53 60 61 62 70 72)
      CUDA_MINIMAL_DRIVER_VERSION=387
      # https://devtalk.nvidia.com/default/topic/1028802/cuda-setup-and-installation/problems-with-cuda-9-1-in-ubuntu-16-04/
      ;;
    9.2*) #.88
      CUDA_ARCHES=(30 32 35 37 50 52 53 60 61 62 70 72)
      CUDA_CODES=(30 32 35 37 50 52 53 60 61 62 70 72)
      CUDA_MINIMAL_DRIVER_VERSION=396
      ;;
    10.0*) #.130
      CUDA_ARCHES=(30 32 35 37 50 52 53 60 61 62 70 72 75)
      CUDA_CODES=(30 32 35 37 50 52 53 60 61 62 70 72 75)
      CUDA_MINIMAL_DRIVER_VERSION=410.48
      ;;
    10.1*) #.105
      CUDA_ARCHES=(30 32 35 37 50 52 53 60 61 62 70 72 75)
      CUDA_CODES=(30 32 35 37 50 52 53 60 61 62 70 72 75)
      CUDA_MINIMAL_DRIVER_VERSION=418.39
      ;;
    10.2*) #.105
      echo "CUDA Version ${CUDA_VERSION} is not programmed in here yet... Using 10.1 values instead" >&2
      CUDA_ARCHES=(30 32 35 37 50 52 53 60 61 62 70 72 75)
      CUDA_CODES=(30 32 35 37 50 52 53 60 61 62 70 72 75)
      CUDA_MINIMAL_DRIVER_VERSION=418.39
      ;;
    # 11*
    # run "strings nvcc | grep compute_" (ARCHES) and "sm_" (CODES) and you'll get a complete list
    *)
      echo "CUDA Version ${CUDA_VERSION} is not programmed in here yet..." >&2
      CUDA_ARCHES=()
      CUDA_CODES=()
      ;;
  esac
}

#**
# .. envvar:: CUDA_SUGGESTED_ARCHES
#
# Suggested "virtual" architectures to compile for
#
# Instead of compiling for every architecture that the :envvar:`CUDA_VERSION` version of ``CUDA`` supports, :envvar:`CUDA_SUGGESTED_ARCHES` is the intersection between :envvar:`CUDA_CARD_ARCHES` and :envvar:`CUDA_ARCHES` so that you compile only for your cards.
#**

#**
# .. envvar:: CUDA_SUGGESTED_CODES
#
# Suggested "real" architectures to compile for
#
# Instead of compiling for every architecture that the :envvar:`CUDA_VERSION` version of ``CUDA`` supports, :envvar:`CUDA_SUGGESTED_CODES` is the intersection between ``CUDA_CARD_CODES`` and :envvar:`CUDA_CODES` so that you compile only for your cards.
#**

#**
# .. envvar:: CUDA_SUGGESTED_PTX
#
# Suggested PTX architectures to compile for
#
# If your graphics card is too new for the :envvar:`CUDA_VERSION` version of ``CUDA``, you will need to compile to a pure virtual architecture (by embedding PTX code in the fatbinary) in order to use it. That way, the real architecture can be JIT (Just-In-Time) compiled for at runtime.
#
# :envvar:`CUDA_SUGGESTED_PTX` identifies the PTX architectures you need to run on newer (unsupported) cards. You can choose to add them to your builds.
#**

#**
# .. envvar:: CUDA_FORWARD_PTX
#
# PTX arch for newer ``CUDA`` cards
#
# In situations where you are making portable fatbinaries, you should compile for every architecture. However, in order to future proof your fatbin for architectures newer than your current version of ``CUDA`` supports, you will need to compile to a pure virtual architecture using the PTX feature so that the real architecture can be JIT (Just-In-Time) compiled.
#
# :envvar:`CUDA_FORWARD_PTX` identifies the fullest featured PTX architecture so that you can choose to add this to your builds.
#**

#**
# .. function:: suggested_architectures
#
# :Output: * :envvar:`CUDA_SUGGESTED_ARCHES` - Suggested virtual architectures for your cards
#          * :envvar:`CUDA_SUGGESTED_CODES` - Suggested real architectures for your cards
#          * :envvar:`CUDA_SUGGESTED_PTX` - Suggested PTX for your cards
#          * :envvar:`CUDA_FORWARD_PTX` - Potential forward compatibility PTX to compile for cards newer than your current ``CUDA`` supports
#
# Calculate suggested architectures
#**
function suggested_architectures()
{
  local x arch y
  local IFS="${IFS}"

  CUDA_SUGGESTED_ARCHES=()
  CUDA_SUGGESTED_CODES=()
  CUDA_SUGGESTED_PTX=()

  # Loop through all the card aches
  for arch in ${CUDA_CARD_ARCHES+"${CUDA_CARD_ARCHES[@]}"}; do
    for x in ${CUDA_ARCHES+"${!CUDA_ARCHES[@]}"}; do
      # If it's an exact match, add it!
      if [ "${CUDA_ARCHES[$x]}" == "${arch}" ]; then
        CUDA_SUGGESTED_ARCHES+=("${arch}")
        continue 2
      # If it's greater than, that means there is no exact match.
      # The last compute checked was the right answer. Use that.
      elif [ "${CUDA_ARCHES[$x]}" -gt "${arch}" ]; then
        # Verify the compute family matches, else you probably have a card that
        # is too old, like a Fermi???
        if [ "${x}" -gt "0" ]; then
          CUDA_SUGGESTED_ARCHES+=("${CUDA_ARCHES[$x-1]}")
        else
          : #: CUDA_SUGGESTED_ARCHES+=("TOOOLD")
        fi
        continue 2
      fi
    done

    # If you get here, either you have a newer arch of an already supported arch,
    # or you have a newer card than this version of cuda supports. Let's check
    # the first case first.
    if [ "${CUDA_ARCHES[$x]:0:1}" == "${arch:0:1}" ]; then
      CUDA_SUGGESTED_ARCHES+=("${CUDA_ARCHES[$x]}")
    else
      # If you get here, that means you have have a newer card than this version
      # of cuda supports. So the best answer is to PTX compile for it.
      CUDA_SUGGESTED_PTX+=("${CUDA_ARCHES[$x]}")
    fi
  done

  for arch in ${CUDA_CARD_ARCHES+"${CUDA_CARD_ARCHES[@]}"}; do
    for x in ${CUDA_CODES+"${!CUDA_CODES[@]}"}; do
      # If it's an exact match, add it!
      if [ "${CUDA_CODES[$x]}" == "${arch}" ]; then
        CUDA_SUGGESTED_CODES+=("${arch}")
        continue 2
      # If it's greater than, that means there is no exact match.
      # The last compute checked was the right answer. Use that.
      elif [ "${CUDA_CODES[$x]}" -gt "${arch}" ]; then
        # Verify the compute family matches, else you probably have a card that
        # is too old, like a Fermi???
        if [ "${x}" == "0" ]; then
          # Too old
          : #CUDA_SUGGESTED_CODES+=("TOOOLD")
        else # if [ "${CUDA_CODES[$x-1]:0:1}" == "${arch:0:1}" ]; This should always be true
          CUDA_SUGGESTED_CODES+=("${CUDA_CODES[$x-1]}")
        fi
        continue 2
      fi
    done

    # If you get here, either you have a newer arch of an already supported arch,
    # or you have a newer card than this version of cuda supports. Let's check
    # the first case first.
    if [ "${CUDA_CODES[$x]:0:1}" == "${arch:0:1}" ]; then
      CUDA_SUGGESTED_CODES+=("${CUDA_CODES[$x]}")
    else
      # If you get here, that means you have have a newer card than this version
      # of cuda supports. So the best answer is to PTX compile for it.
      CUDA_SUGGESTED_PTX+=("${CUDA_CODES[$x]}")
    fi
  done

  CUDA_FORWARD_PTX=${CUDA_ARCHES+"${CUDA_ARCHES[${#CUDA_ARCHES[@]}-1]}"}

  IFS=$'\n'
  CUDA_SUGGESTED_ARCHES=($(sort -u <<< ${CUDA_SUGGESTED_ARCHES+"${CUDA_SUGGESTED_ARCHES[*]}"}))
  CUDA_SUGGESTED_CODES=($(sort -u <<< ${CUDA_SUGGESTED_CODES+"${CUDA_SUGGESTED_CODES[*]}"}))
  CUDA_SUGGESTED_PTX=($(sort -u <<< ${CUDA_SUGGESTED_PTX+"${CUDA_SUGGESTED_PTX[*]}"}))
}

#**
# .. function:: cmake_cuda_flags
#
# :Parameters: * :envvar:`CUDA_SUGGESTED_ARCHES` - List of virtual architectures to compile
#              * :envvar:`CUDA_SUGGESTED_CODES` - Matching list of real architectures to compile
#              * [:envvar:`CUDA_SUGGESTED_PTX`] - Optional list of PTX architectures to compile
# :Output: *stdout* - echoes out the value of the target_CUDA_architectures
#
# Generate ``CUDA`` flags for CMake
#
# Modern CMake installs include a FindCUDA.cmake script which calls the select_compute_arch.cmake script (https://goo.gl/uZvAjR). It uses a limited version of the tables that :file:`cuda_info.bsh` uses and is prone to being out of date.
#
# This function will calculate the suggested value of target_CUDA_architectures for CMake's:
#
#   FindCUDA.cmake:select_compute_arch.cmake:CUDA_SELECT_NVCC_ARCH_FLAGS
#
# You will need to find where this is used and set the variable accordingly.
#
# .. rubric:: Example
#
# For example, PyTorch's CMake contains:
#
# .. code-block:: bash
#
#   CUDA_SELECT_NVCC_ARCH_FLAGS(NVCC_FLAGS_EXTRA $ENV{TORCH_CUDA_ARCH_LIST})
#
# Setting the environment variable ``TORCH_CUDA_ARCH_LIST`` to the output of :func:`cmake_cuda_flags` will result in using the desired ``CUDA`` architecture and code versions.
#
# To add the :envvar:`CUDA_FORWARD_PTX`, run:
#
# .. code-block:: bash
#
#   CUDA_SUGGESTED_PTX+=(${CUDA_FORWARD_PTX})
#
# before calling :func:`cmake_cuda_flags`
#**
function cmake_cuda_flags()
{
  local cmake=()
  local x
  local y
  local ptx
  local OLD_IFS="${IFS}"

  for i in "${!CUDA_SUGGESTED_ARCHES[@]}"; do
    if [ "${CUDA_SUGGESTED_ARCHES[$i]}" == "${CUDA_SUGGESTED_CODES[$i]}" ]; then
      x="${CUDA_SUGGESTED_ARCHES[$i]}"
      x="${x:0:${#x}-1}.${x:${#x}-1:1}"
    else
      x="${CUDA_SUGGESTED_CODES[$i]}"
      y="${CUDA_SUGGESTED_ARCHES[$i]}"
      x="${x:0:${#x}-1}.${x:${#x}-1:1}"
      y="${y:0:${#y}-1}.${y:${#y}-1:1}"
      x="${x}(${y})"
    fi
    cmake+=($x)
  done

  ptx=(${CUDA_SUGGESTED_PTX+"${CUDA_SUGGESTED_PTX[@]}"})
  IFS=$'\n'
  ptx=($(echo "${ptx+"${ptx[*]}"}" | sort -u))
  IFS="${OLD_IFS}"
  for i in "${!ptx[@]}"; do
    x="${CUDA_SUGGESTED_PTX[$i]}"
    x="${x:0:${#x}-1}.${x:${#x}-1:1}"
    cmake+=("${x}+PTX")
  done

  echo -n ${cmake+"${cmake[*]}"}
}

# Call all of the CUDA discovery functions

if [ "${CUDA_VERSION+set}" != "set" ]; then
  discover_cuda_versions
fi

if [ "${CUDA_DISCOVER-}" == "1" ] && [ "${CUDA_VERSION+set}" == "set" ]; then
  discover_cuda_info
fi
#unset CUDA_DISCOVER # ??? To prevent multiple calls

cuda_capabilities
suggested_architectures
